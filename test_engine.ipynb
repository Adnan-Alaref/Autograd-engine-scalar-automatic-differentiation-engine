{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c969f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from autograd.engine import Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7758d13d",
   "metadata": {},
   "source": [
    "âœ… Test 1: test_sanity_check()\n",
    "* Purpose: Basic sanity test â€” checks whether your autograd engine correctly computes forward values and backward gradients for a simple expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d71daeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sanity_check():\n",
    "\n",
    "    x = Value(-4.0)\n",
    "    z = 2 * x + 2 + x\n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    xmg, ymg = x, y\n",
    "\n",
    "    x = torch.Tensor([-4.0]).double()\n",
    "    x.requires_grad = True\n",
    "    z = 2 * x + 2 + x\n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    xpt, ypt = x, y\n",
    "\n",
    "    # forward pass went well\n",
    "    assert ymg.data == ypt.data.item()\n",
    "    # backward pass went well\n",
    "    assert xmg.grad == xpt.grad.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3c2c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If both assertions pass â†’ your engine matches PyTorch.\n",
    "test_sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6675fb9",
   "metadata": {},
   "source": [
    "#### ðŸ§® Test 2: test_more_ops()\n",
    "* Purpose: Complex expression test â€” ensures your implementation handles mixed operations, chaining, broadcasting, and nonlinearities (ReLU).\n",
    "* This test runs a longer and more complicated sequence of operations, involving:\n",
    ">Addition, multiplication, power (**), ReLU, and division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8900e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_more_ops():\n",
    "\n",
    "    a = Value(-4.0)\n",
    "    b = Value(2.0)\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c += c + 1\n",
    "    c += 1 + c + (-a)\n",
    "    d += d * 2 + (b + a).relu()\n",
    "    d += 3 * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g += 10.0 / f\n",
    "    g.backward()\n",
    "    amg, bmg, gmg = a, b, g\n",
    "\n",
    "    a = torch.Tensor([-4.0]).double()\n",
    "    b = torch.Tensor([2.0]).double()\n",
    "    a.requires_grad = True\n",
    "    b.requires_grad = True\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c = c + c + 1\n",
    "    c = c + 1 + c + (-a)\n",
    "    d = d + d * 2 + (b + a).relu()\n",
    "    d = d + 3 * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g = g + 10.0 / f\n",
    "    g.backward()\n",
    "    apt, bpt, gpt = a, b, g\n",
    "\n",
    "    tol = 1e-6\n",
    "    # forward pass went well\n",
    "    assert abs(gmg.data - gpt.data.item()) < tol\n",
    "    # backward pass went well\n",
    "    assert abs(amg.grad - apt.grad.item()) < tol\n",
    "    assert abs(bmg.grad - bpt.grad.item()) < tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2902d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all assertions hold â†’ your engine produces results numerically identical to PyTorch.\n",
    "test_more_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16e8cc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.7041\n",
      "138.8338\n",
      "645.5773\n"
     ]
    }
   ],
   "source": [
    "a = Value(-4.0)\n",
    "b = Value(2.0)\n",
    "c = a + b\n",
    "d = a * b + b**3\n",
    "c += c + 1\n",
    "c += 1 + c + (-a)\n",
    "d += d * 2 + (b + a).relu()\n",
    "d += 3 * d + (b - a).relu()\n",
    "e = c - d\n",
    "f = e**2\n",
    "g = f / 2.0\n",
    "g += 10.0 / f\n",
    "print(f'{g.data:.4f}') # prints 24.7041, the outcome of this forward pass\n",
    "g.backward()\n",
    "print(f'{a.grad:.4f}') # prints 138.8338, i.e. the numerical value of dg/da\n",
    "print(f'{b.grad:.4f}') # prints 645.5773, i.e. the numerical value of dg/db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b113d162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§© BASIC TESTS\n",
      "x = Value(data=2.0)\n",
      "y = Value(data=3.0)\n",
      "z = Value(data=4.0)\n",
      "\n",
      "ðŸ”¹ Addition:\n",
      "x + y = Value(data=5.0)\n",
      "x + 2 = Value(data=4.0)\n",
      "2 + x = Value(data=4.0)\n",
      "\n",
      "ðŸ”¹ Subtraction:\n",
      "y - x = Value(data=1.0)\n",
      "5 - x = Value(data=3.0)\n",
      "x - 1 = Value(data=1.0)\n",
      "\n",
      "ðŸ”¹ Multiplication:\n",
      "x * y = Value(data=6.0)\n",
      "x * 2 = Value(data=4.0)\n",
      "2 * x = Value(data=4.0)\n",
      "\n",
      "ðŸ”¹ Power:\n",
      "x ** 2 = Value(data=4.0)\n",
      "2 ** x = Value(data=4.0)\n",
      "\n",
      "ðŸ”¹ Division:\n",
      "y / x = Value(data=1.5)\n",
      "x / 2 = Value(data=1.0)\n",
      "2 / x = Value(data=1.0)\n",
      "\n",
      "ðŸ§© COMPLEX EXPRESSIONS\n",
      "expr1 = Value(data=20.0)\n",
      "expr2 = Value(data=0.25)\n",
      "expr3 = Value(data=8.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ§© BASIC TESTS\")\n",
    "x = Value(2)\n",
    "y = Value(3)\n",
    "z = Value(4)\n",
    "\n",
    "print(\"x =\", x)\n",
    "print(\"y =\", y)\n",
    "print(\"z =\", z)\n",
    "\n",
    "print(\"\\nðŸ”¹ Addition:\")\n",
    "print(\"x + y =\", x + y)\n",
    "print(\"x + 2 =\", x + 2)\n",
    "print(\"2 + x =\", 2 + x)\n",
    "\n",
    "print(\"\\nðŸ”¹ Subtraction:\")\n",
    "print(\"y - x =\", y - x)\n",
    "print(\"5 - x =\", 5 - x)\n",
    "print(\"x - 1 =\", x - 1)\n",
    "\n",
    "print(\"\\nðŸ”¹ Multiplication:\")\n",
    "print(\"x * y =\", x * y)\n",
    "print(\"x * 2 =\", x * 2)\n",
    "print(\"2 * x =\", 2 * x)\n",
    "\n",
    "print(\"\\nðŸ”¹ Power:\")\n",
    "print(\"x ** 2 =\", x ** 2)\n",
    "print(\"2 ** x =\", 2 ** x)\n",
    "\n",
    "print(\"\\nðŸ”¹ Division:\")\n",
    "print(\"y / x =\", y / x)\n",
    "print(\"x / 2 =\", x / 2)\n",
    "print(\"2 / x =\", 2 / x)\n",
    "\n",
    "# Test composite expressions\n",
    "print(\"\\nðŸ§© COMPLEX EXPRESSIONS\")\n",
    "expr1 = (x + y) * z\n",
    "expr2 = (x - 1) / (y + 1)\n",
    "expr3 = (x * y) + (z / x)\n",
    "# This will give ZeroDivisionError: division by zero(i code it in call value)  \n",
    "# expr4 = (2 + x) ** 2 / (3 - y)  \n",
    "\n",
    "print(\"expr1 =\", expr1)\n",
    "print(\"expr2 =\", expr2)\n",
    "print(\"expr3 =\", expr3)\n",
    "# print(\"expr4 =\", expr4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
